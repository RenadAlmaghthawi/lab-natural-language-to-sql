{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yFnrczEWDMm"
      },
      "source": [
        "# Natural language to SQL\n",
        "\n",
        "**Run in [Google Colab](https://colab.research.google.com/) For GPU.**\n",
        "\n",
        "This model have  Mistral as a base and it has been fine-tuned to excel in SQL code generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwUhBRwaLVZI"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('HF_TOKEN')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VNBGXh9V952",
        "outputId": "f43c3765-fa17-4247-dab7-63f98b19309d",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting git+https://github.com/huggingface/accelerate.git\n",
            "  Cloning https://github.com/huggingface/accelerate.git to /tmp/pip-req-build-ewloxyhw\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate.git /tmp/pip-req-build-ewloxyhw\n",
            "  Resolved https://github.com/huggingface/accelerate.git to commit b451956fd69a135efc283aadaa478f0d33fcbe6a\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.7.0.dev0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.7.0.dev0) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==1.7.0.dev0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate==1.7.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.7.0.dev0) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.7.0.dev0) (0.30.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.7.0.dev0) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate==1.7.0.dev0) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate==1.7.0.dev0) (2025.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate==1.7.0.dev0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate==1.7.0.dev0) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate==1.7.0.dev0) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0.dev0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0.dev0) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0.dev0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0.dev0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0.dev0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0.dev0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0.dev0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0.dev0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0.dev0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0.dev0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0.dev0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0.dev0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0.dev0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0.dev0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0.dev0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0.dev0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0.dev0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate==1.7.0.dev0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate==1.7.0.dev0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate==1.7.0.dev0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate==1.7.0.dev0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate==1.7.0.dev0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate==1.7.0.dev0) (2025.1.31)\n",
            "Collecting git+https://github.com/huggingface/transformers.git\n",
            "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-j5pc5e_1\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-j5pc5e_1\n",
            "  Resolved https://github.com/huggingface/transformers.git to commit 1d9743edc2030e8444d5bdffa910a3d6822bcf2d\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.0.dev0) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.0.dev0) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.0.dev0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.0.dev0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.0.dev0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.0.dev0) (2025.1.31)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.5)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "#Install the lastest versions of peft & transformers library recommended\n",
        "#if you want to work with the most recent models\n",
        "!pip install -q git+https://github.com/huggingface/peft.git\n",
        "!pip install git+https://github.com/huggingface/accelerate.git\n",
        "!pip install git+https://github.com/huggingface/transformers.git\n",
        "!pip install bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "U1mZ27vbXBCE"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "import torch\n",
        "import accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rotsX3i-XLJS"
      },
      "outputs": [],
      "source": [
        "model_name = \"defog/sqlcoder-7b\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fHZsPTa5yun"
      },
      "source": [
        "We need to create the Quantization configuration to load the Model.\n",
        "\n",
        "It is a large model and I want it to fit in a 16GB GPU, I'm going to use a 4 bits quantization.\n",
        "\n",
        "If you want to learn more about quantization, refer to this article: [QLoRA: Training a Large Language Model on a 16GB GPU.](https://medium.com/towards-artificial-intelligence/qlora-training-a-large-language-model-on-a-16gb-gpu-00ea965667c1)\n",
        "\n",
        "You can try to use this model in a 8 bit quantizations and check in you see any improvements in the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Oio2Fm7GXa6K"
      },
      "outputs": [],
      "source": [
        "bnb_config = BitsAndBytesConfig(\n",
        "  load_in_4bit=True,\n",
        "  bnb_4bit_use_double_quant=True,\n",
        "  bnb_4bit_quant_type=\"nf4\",\n",
        "  bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "915oTn7T6fvW"
      },
      "source": [
        "To load the model I pass to the AutoModelForCasualLM teh quantization configurations, and HuggingFace take care of all the hard work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Q8-VpiCBXcst",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "7cfbbcb63b8a47ff90cb3d69d09c9171",
            "32a88bfad79348d5b4af4aebf05ea870",
            "9891886f7e34422dad03b38dba8a942b",
            "07e11b7506764d89a0d51a36d7d04baf",
            "45f367376a96490a9203a4a664f715b7",
            "f8942b4deb354824993d92a2cb78dae6",
            "f24918c49953451386f682499bf1b0c5",
            "d6f9f6548ecb4195ae76b4eff9d3c1e4",
            "01b9d2d4354242df9ed6f112c5171d29",
            "bffd7a3c78b341b9b510453d56321c91",
            "816bc43de88245f98747cf6281a6a10c",
            "4f0890da1d9d49a7a6eeabe5ddf6db21",
            "05652939a26f48bdbed892a75a1582c5",
            "d73d76d7a13f40f6bd705a3590d0f283",
            "70d51cd1a265482da0d0b555c0dafd86",
            "fef14a182cf54e1a8bfe5668d66c40fa",
            "6b93cfb0c5674adf82d20f35bd1802d9",
            "066a7547905f41f0b3bc7593ccd91ddb",
            "cb095a039b394ebeba30847d4fb37f7b",
            "7034033f53fe4d43a6d6a9272cbd7cd5",
            "23ae95fe17334ee1b46b7bf5b6b976c1",
            "9151606613b3484f80e3f7676cfd9e2d",
            "3f2db411b29d430ebc2a0b875e210b23",
            "799495d8f0a4481eaab853024567efe2",
            "3f06208ca5954d1aa06cd468bbd8a7df",
            "c9dc148940344bcba07953a215006209",
            "83cdfaff81d1467fb0dad8147ac87ca2",
            "05dda387758149c8bad4fd8b342b2667",
            "0a6ee0ea38124042801d4a3f4de9340d",
            "37a5cd5b2e074e9782046ed02ff12c51",
            "a5eed6c8cf824618b5087ee281002bba",
            "b1ec93f16a5c49e9b31c11850f1d182e",
            "14047118b8944f22bef12b626b666a7e",
            "e84cd88ced7b4bcd9619657ac0cb822f",
            "ca69fbe6da6d4faea97c525c667a7269",
            "ad44f8a751f94777bf1dba4878623408",
            "722b8a0d17f74a058bf6e718c4d6d1b5",
            "10675ff63f1740a0af7e477f879dee41",
            "cfe1d3c8573742d3b7b74d8bed17fe74",
            "ba036d7588dc457e8c5f87a433f6f65b",
            "1d24e8c001ed4000bcbfd1d72f4a4a17",
            "ceeca5f73354449f8a61eb96a4d6c695",
            "52cd63335c27421aa7a808e935779c0f",
            "d23dc2035fdb430ca93b39acff435691"
          ]
        },
        "collapsed": true,
        "outputId": "7f51a13f-9324-4312-8e56-cab21ca4ce5a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7cfbbcb63b8a47ff90cb3d69d09c9171"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model-00001-of-00002.bin:  97%|#########6| 9.62G/9.94G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f0890da1d9d49a7a6eeabe5ddf6db21"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3f2db411b29d430ebc2a0b875e210b23"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e84cd88ced7b4bcd9619657ac0cb822f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "foundation_model = AutoModelForCausalLM.from_pretrained(model_name,\n",
        "                    quantization_config=bnb_config,\n",
        "                    device_map='auto',\n",
        "                    use_cache = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "E2Oz6Sm8X5Qo",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "eos_token_id = tokenizer.convert_tokens_to_ids([\"```\"])[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NV-Qk6327Z30"
      },
      "source": [
        "This function wraps the call to *model.generate*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "l4vEDNRGtvdn"
      },
      "outputs": [],
      "source": [
        "#this function returns the outputs from the model received, and inputs.\n",
        "def get_outputs(model, inputs, max_new_tokens=400):\n",
        "    outputs = model.generate(\n",
        "        input_ids=inputs[\"input_ids\"],\n",
        "        attention_mask=inputs[\"attention_mask\"],\n",
        "        num_return_sequences=1,\n",
        "        eos_token_id=eos_token_id,\n",
        "        pad_token_id=eos_token_id,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        do_sample=False,\n",
        "        num_beams=5\n",
        "    )\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y88PVExjKCvQ"
      },
      "source": [
        "# Prompt without Shots.\n",
        "In this first PROMPT we are going to give Instructions to the model and pass the structure of the Database.\n",
        "\n",
        "The instructions are significantly different from those we are passing to GPT-3.5-Turbo. This model is really well fine-tuned, but it is smaller than GPT-3.5.\n",
        "\n",
        "We need to be more clear with the instructions, as it does not have the same capacity to understand our orders as GPT-3.5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "U8K4XWDQJH_p"
      },
      "outputs": [],
      "source": [
        "sp_nl2sql = \"\"\"\n",
        "  ### Instructions:\n",
        "Your task is convert a question into a SQL query, given a SQL database schema.\n",
        "Adhere to these rules:\n",
        "- **Deliberately go through the question and database schema word by word** to appropriately answer the question\n",
        "\n",
        "    ### Input\n",
        "    Generate a SQL query that answers the question below.\n",
        "    This query will run on a database whose schema is represented in this string:\n",
        "\n",
        "    CREATE TABLE Customers (\n",
        "    customer_id INT PRIMARY KEY,\n",
        "    name TEXT,\n",
        "    email TEXT\n",
        ");\n",
        "\n",
        "CREATE TABLE Orders (\n",
        "    order_id INT PRIMARY KEY,\n",
        "    customer_id INT,\n",
        "    order_date DATE,\n",
        "    total_amount DECIMAL,\n",
        "    FOREIGN KEY (customer_id) REFERENCES Customers(customer_id)\n",
        ");\n",
        "\n",
        "CREATE TABLE Products (\n",
        "    product_id INT PRIMARY KEY,\n",
        "    name TEXT,\n",
        "    price DECIMAL\n",
        ");\n",
        "\n",
        "CREATE TABLE OrderItems (\n",
        "    order_item_id INT PRIMARY KEY,\n",
        "    order_id INT,\n",
        "    product_id INT,\n",
        "    quantity INT,\n",
        "    FOREIGN KEY (order_id) REFERENCES Orders(order_id),\n",
        "    FOREIGN KEY (product_id) REFERENCES Products(product_id)\n",
        ");\n",
        "\n",
        "\n",
        "    ### Response\n",
        "    Based on your instructions, here is the SQL query I have generated to answer the question\n",
        "    `{question}`:\n",
        "    ```sql3\n",
        "    \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "tIgEZpmSlG0I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7a09887-3f1e-47af-dbe6-a712207c2692"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  ### Instructions:\n",
            "Your task is convert a question into a SQL query, given a SQL database schema.\n",
            "Adhere to these rules:\n",
            "- **Deliberately go through the question and database schema word by word** to appropriately answer the question\n",
            "\n",
            "    ### Input\n",
            "    Generate a SQL query that answers the question below.\n",
            "    This query will run on a database whose schema is represented in this string:\n",
            "\n",
            "    CREATE TABLE Customers (\n",
            "    customer_id INT PRIMARY KEY,\n",
            "    name TEXT,\n",
            "    email TEXT\n",
            ");\n",
            "\n",
            "CREATE TABLE Orders (\n",
            "    order_id INT PRIMARY KEY,\n",
            "    customer_id INT,\n",
            "    order_date DATE,\n",
            "    total_amount DECIMAL,\n",
            "    FOREIGN KEY (customer_id) REFERENCES Customers(customer_id)\n",
            ");\n",
            "\n",
            "CREATE TABLE Products (\n",
            "    product_id INT PRIMARY KEY,\n",
            "    name TEXT,\n",
            "    price DECIMAL\n",
            ");\n",
            "\n",
            "CREATE TABLE OrderItems (\n",
            "    order_item_id INT PRIMARY KEY,\n",
            "    order_id INT,\n",
            "    product_id INT,\n",
            "    quantity INT,\n",
            "    FOREIGN KEY (order_id) REFERENCES Orders(order_id),\n",
            "    FOREIGN KEY (product_id) REFERENCES Products(product_id)\n",
            ");\n",
            "\n",
            "\n",
            "    ### Response\n",
            "    Based on your instructions, here is the SQL query I have generated to answer the question\n",
            "    `What are the names of all customers who placed an order in January?`:\n",
            "    ```sql3\n",
            "    \n"
          ]
        }
      ],
      "source": [
        "sp_nl2sql = sp_nl2sql.format(question=\"What are the names of all customers who placed an order in January?\")\n",
        "print(sp_nl2sql)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Mp3TDRQtltX9"
      },
      "outputs": [],
      "source": [
        "input_sentences = tokenizer(sp_nl2sql, return_tensors=\"pt\").to('cuda')\n",
        "response = get_outputs(foundation_model, input_sentences, max_new_tokens=400)\n",
        "SQL = tokenizer.batch_decode(response, skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "hWouSh-7rpCk"
      },
      "outputs": [],
      "source": [
        "#Empty the cache in orde to do more calls without problems.\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "g0V5XuDp0sCi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "285175d3-e691-4500-db0f-c7bf779622e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT c.name FROM Customers c JOIN Orders o ON c.customer_id = o.customer_id WHERE date_part('year', o.order_date) = date_part('year', CURRENT_DATE) AND date_part('month', o.order_date) = 1;\n"
          ]
        }
      ],
      "source": [
        "print(SQL[0].split(\"```sql3\")[-1].split(\"```\")[0].split(\";\")[0].strip() + \";\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKrjztcK-zDm"
      },
      "source": [
        "The SQL Order is correct."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0hogn4fKP1f"
      },
      "source": [
        "#Prompt with shots OpenAI Style.\n",
        "In this second prompt we are going to add some Shots with samples to see if our SQL style affects the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "qNPXi3twuN7-"
      },
      "outputs": [],
      "source": [
        "sp_nl2sql2 = \"\"\"\n",
        "### Instructions:\n",
        "Your task is convert a question into a SQL query, given a SQL database schema.\n",
        "Adhere to these rules:\n",
        "- **Deliberately go through the question and database schema word by word** to appropriately answer the question\n",
        "\n",
        "    ### Input\n",
        "    Generate a SQL query that answers the question below.\n",
        "    This query will run on a database whose schema is represented in this string:\n",
        "\n",
        "   CREATE TABLE Customers (\n",
        "    customer_id INT PRIMARY KEY,\n",
        "    name TEXT,\n",
        "    email TEXT\n",
        ");\n",
        "\n",
        "CREATE TABLE Orders (\n",
        "    order_id INT PRIMARY KEY,\n",
        "    customer_id INT,\n",
        "    order_date DATE,\n",
        "    total_amount DECIMAL,\n",
        "    FOREIGN KEY (customer_id) REFERENCES Customers(customer_id)\n",
        ");\n",
        "\n",
        "CREATE TABLE Products (\n",
        "    product_id INT PRIMARY KEY,\n",
        "    name TEXT,\n",
        "    price DECIMAL\n",
        ");\n",
        "\n",
        "CREATE TABLE OrderItems (\n",
        "    order_item_id INT PRIMARY KEY,\n",
        "    order_id INT,\n",
        "    product_id INT,\n",
        "    quantity INT,\n",
        "    FOREIGN KEY (order_id) REFERENCES Orders(order_id),\n",
        "    FOREIGN KEY (product_id) REFERENCES Products(product_id)\n",
        ");\n",
        "\n",
        "  ### Response\n",
        "\n",
        "    Question1: List all product names and their prices.\n",
        "    ```sql\n",
        "    SELECT name, price FROM Products;\n",
        "\n",
        "    Question2: Get the number of orders placed by each customer\n",
        "    ```sql\n",
        "    SELECT c.name, COUNT(o.order_id) AS order_count\n",
        "    FROM Customers c\n",
        "    JOIN Orders o ON c.customer_id = o.customer_id\n",
        "    GROUP BY c.name;\n",
        "\n",
        "      Based on your instructions, here is the SQL query I have generated to answer the question\n",
        "      `{question}`:\n",
        "      ```sql3\n",
        "      \"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "7vy338SDLr5u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b26d08ff-2f00-4549-c867-0dc5f5233da4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### Instructions:\n",
            "Your task is convert a question into a SQL query, given a SQL database schema.\n",
            "Adhere to these rules:\n",
            "- **Deliberately go through the question and database schema word by word** to appropriately answer the question\n",
            "\n",
            "    ### Input\n",
            "    Generate a SQL query that answers the question below.\n",
            "    This query will run on a database whose schema is represented in this string:\n",
            "\n",
            "   CREATE TABLE Customers (\n",
            "    customer_id INT PRIMARY KEY,\n",
            "    name TEXT,\n",
            "    email TEXT\n",
            ");\n",
            "\n",
            "CREATE TABLE Orders (\n",
            "    order_id INT PRIMARY KEY,\n",
            "    customer_id INT,\n",
            "    order_date DATE,\n",
            "    total_amount DECIMAL,\n",
            "    FOREIGN KEY (customer_id) REFERENCES Customers(customer_id)\n",
            ");\n",
            "\n",
            "CREATE TABLE Products (\n",
            "    product_id INT PRIMARY KEY,\n",
            "    name TEXT,\n",
            "    price DECIMAL\n",
            ");\n",
            "\n",
            "CREATE TABLE OrderItems (\n",
            "    order_item_id INT PRIMARY KEY,\n",
            "    order_id INT,\n",
            "    product_id INT,\n",
            "    quantity INT,\n",
            "    FOREIGN KEY (order_id) REFERENCES Orders(order_id),\n",
            "    FOREIGN KEY (product_id) REFERENCES Products(product_id)\n",
            ");\n",
            "\n",
            "  ### Response\n",
            "\n",
            "    Question1: List all product names and their prices.\n",
            "    ```sql\n",
            "    SELECT name, price FROM Products;\n",
            "\n",
            "    Question2: Get the number of orders placed by each customer\n",
            "    ```sql\n",
            "    SELECT c.name, COUNT(o.order_id) AS order_count\n",
            "    FROM Customers c\n",
            "    JOIN Orders o ON c.customer_id = o.customer_id\n",
            "    GROUP BY c.name;\n",
            "\n",
            "      Based on your instructions, here is the SQL query I have generated to answer the question\n",
            "      `What are the names of all customers who placed an order in January?`:\n",
            "      ```sql3\n",
            "      \n"
          ]
        }
      ],
      "source": [
        "sp_nl2sql2 = sp_nl2sql2.format(question=\"What are the names of all customers who placed an order in January?\")\n",
        "(print(sp_nl2sql2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Cvk9hJfhLwQJ"
      },
      "outputs": [],
      "source": [
        "input_sentences = tokenizer(sp_nl2sql2, return_tensors=\"pt\").to('cuda')\n",
        "response = get_outputs(foundation_model, input_sentences, max_new_tokens=400)\n",
        "SQL = tokenizer.batch_decode(response, skip_special_tokens=True)\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "EQOyi8ZOL1mr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5f7668a-81a8-40fe-8d6d-67f8a185e9b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT c.name\n",
            "       FROM Customers c\n",
            "       JOIN Orders o ON c.customer_id = o.customer_id\n",
            "       WHERE date_part('year', o.order_date) = date_part('year', '2020-01-01')\n",
            "       AND date_part('month', o.order_date) = date_part('month', '2020-01-01')\n",
            "       AND date_part('day', o.order_date) BETWEEN date_part('day', '2020-01-01') AND date_part('day', '2020-01-31');\n"
          ]
        }
      ],
      "source": [
        "print(SQL[0].split(\"```sql3\")[-1].split(\"```\")[0].split(\";\")[0].strip() + \";\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6S6gI_fNtFk"
      },
      "source": [
        "#Prompt with Shots in Sample Style.\n",
        "\n",
        "In this prompt, we will place the examples in a separate section, and in the instructions, we will instruct the model to pay attention to them in order to generate the SQL commands."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "oHSF1l3xNscJ"
      },
      "outputs": [],
      "source": [
        "sp_nl2sql3b = \"\"\"\n",
        "### Instructions:\n",
        "Your task is convert a question into a SQL query, given a SQL database schema.\n",
        "Adhere to these rules:\n",
        "- **Deliberately go through the question and database schema word by word** to appropriately answer the question\n",
        "\n",
        "    ### Input\n",
        "    Generate a SQL query that answers the question below.\n",
        "    This query will run on a database whose schema is represented in this string:\n",
        "\n",
        "    CREATE TABLE Customers (\n",
        "    customer_id INT PRIMARY KEY,\n",
        "    name TEXT,\n",
        "    email TEXT\n",
        ");\n",
        "\n",
        "CREATE TABLE Orders (\n",
        "    order_id INT PRIMARY KEY,\n",
        "    customer_id INT,\n",
        "    order_date DATE,\n",
        "    total_amount DECIMAL,\n",
        "    FOREIGN KEY (customer_id) REFERENCES Customers(customer_id)\n",
        ");\n",
        "\n",
        "CREATE TABLE Products (\n",
        "    product_id INT PRIMARY KEY,\n",
        "    name TEXT,\n",
        "    price DECIMAL\n",
        ");\n",
        "\n",
        "CREATE TABLE OrderItems (\n",
        "    order_item_id INT PRIMARY KEY,\n",
        "    order_id INT,\n",
        "    product_id INT,\n",
        "    quantity INT,\n",
        "    FOREIGN KEY (order_id) REFERENCES Orders(order_id),\n",
        "    FOREIGN KEY (product_id) REFERENCES Products(product_id)\n",
        ");\n",
        "\n",
        "\n",
        "    ### Samples\n",
        "\n",
        "    Question1: List all customer names.\n",
        "    ```sql\n",
        "    SELECT name FROM Customers;\n",
        "\n",
        "    Question2: Show names of all products that were ordered more than once\n",
        "    ```sql\n",
        "    SELECT p.name\n",
        "    FROM Products p\n",
        "    JOIN OrderItems oi ON p.product_id = oi.product_id\n",
        "    GROUP BY p.name\n",
        "    HAVING SUM(oi.quantity) > 1;\n",
        "\n",
        "    Question3:Retrieve the total number of orders per customer\n",
        "    ```sql\n",
        "    SELECT c.name, COUNT(o.order_id) AS order_count\n",
        "    FROM Customers c\n",
        "    JOIN Orders o ON c.customer_id = o.customer_id\n",
        "    GROUP BY c.name;\n",
        "\n",
        "\n",
        "    ### Response\n",
        "    Based on your instructions, here is the SQL query I have generated to answer the question\n",
        "    `{question}`:\n",
        "    ```sql3\n",
        "    \"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "DCfbmvDyOS-u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f546bacc-7c44-400d-ff20-7df54b6de58b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### Instructions:\n",
            "Your task is convert a question into a SQL query, given a SQL database schema.\n",
            "Adhere to these rules:\n",
            "- **Deliberately go through the question and database schema word by word** to appropriately answer the question\n",
            "\n",
            "    ### Input\n",
            "    Generate a SQL query that answers the question below.\n",
            "    This query will run on a database whose schema is represented in this string:\n",
            "\n",
            "    CREATE TABLE Customers (\n",
            "    customer_id INT PRIMARY KEY,\n",
            "    name TEXT,\n",
            "    email TEXT\n",
            ");\n",
            "\n",
            "CREATE TABLE Orders (\n",
            "    order_id INT PRIMARY KEY,\n",
            "    customer_id INT,\n",
            "    order_date DATE,\n",
            "    total_amount DECIMAL,\n",
            "    FOREIGN KEY (customer_id) REFERENCES Customers(customer_id)\n",
            ");\n",
            "\n",
            "CREATE TABLE Products (\n",
            "    product_id INT PRIMARY KEY,\n",
            "    name TEXT,\n",
            "    price DECIMAL\n",
            ");\n",
            "\n",
            "CREATE TABLE OrderItems (\n",
            "    order_item_id INT PRIMARY KEY,\n",
            "    order_id INT,\n",
            "    product_id INT,\n",
            "    quantity INT,\n",
            "    FOREIGN KEY (order_id) REFERENCES Orders(order_id),\n",
            "    FOREIGN KEY (product_id) REFERENCES Products(product_id)\n",
            ");\n",
            "\n",
            "\n",
            "    ### Samples\n",
            "\n",
            "    Question1: List all customer names.\n",
            "    ```sql\n",
            "    SELECT name FROM Customers;\n",
            "\n",
            "    Question2: Show names of all products that were ordered more than once\n",
            "    ```sql\n",
            "    SELECT p.name\n",
            "    FROM Products p\n",
            "    JOIN OrderItems oi ON p.product_id = oi.product_id\n",
            "    GROUP BY p.name\n",
            "    HAVING SUM(oi.quantity) > 1;\n",
            "\n",
            "    Question3:Retrieve the total number of orders per customer\n",
            "    ```sql\n",
            "    SELECT c.name, COUNT(o.order_id) AS order_count\n",
            "    FROM Customers c\n",
            "    JOIN Orders o ON c.customer_id = o.customer_id\n",
            "    GROUP BY c.name;\n",
            "\n",
            "\n",
            "    ### Response\n",
            "    Based on your instructions, here is the SQL query I have generated to answer the question\n",
            "    `What are the names of all customers who placed an order in January?`:\n",
            "    ```sql3\n",
            "    \n"
          ]
        }
      ],
      "source": [
        "sp_nl2sql3 = sp_nl2sql3b.format(question=\"What are the names of all customers who placed an order in January?\")\n",
        "print (sp_nl2sql3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "VxsIf4KBOWCk"
      },
      "outputs": [],
      "source": [
        "input_sentences = tokenizer(sp_nl2sql3, return_tensors=\"pt\").to('cuda')\n",
        "response = get_outputs(foundation_model, input_sentences, max_new_tokens=400)\n",
        "SQL = tokenizer.batch_decode(response, skip_special_tokens=True)\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "_sE5_a8jOaJ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96797e2e-7615-4f18-f868-3714d085bc70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT c.name\n",
            "    FROM Customers c\n",
            "    JOIN Orders o ON c.customer_id = o.customer_id\n",
            "    WHERE date_part('year', o.order_date) = date_part('year', CURRENT_DATE)\n",
            "    AND date_part('month', o.order_date) = 1;\n"
          ]
        }
      ],
      "source": [
        "print(SQL[0].split(\"```sql3\")[-1].split(\"```\")[0].split(\";\")[0].strip() + \";\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5OgzBzKNHzn"
      },
      "source": [
        "#Now the question in spanish.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "EQuJNMjNFU6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbe0dae6-fdb2-4b1d-e8cb-c04f759f67d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### Instructions:\n",
            "Your task is convert a question into a SQL query, given a SQL database schema.\n",
            "Adhere to these rules:\n",
            "- **Deliberately go through the question and database schema word by word** to appropriately answer the question\n",
            "\n",
            "    ### Input\n",
            "    Generate a SQL query that answers the question below.\n",
            "    This query will run on a database whose schema is represented in this string:\n",
            "\n",
            "    CREATE TABLE Customers (\n",
            "    customer_id INT PRIMARY KEY,\n",
            "    name TEXT,\n",
            "    email TEXT\n",
            ");\n",
            "\n",
            "CREATE TABLE Orders (\n",
            "    order_id INT PRIMARY KEY,\n",
            "    customer_id INT,\n",
            "    order_date DATE,\n",
            "    total_amount DECIMAL,\n",
            "    FOREIGN KEY (customer_id) REFERENCES Customers(customer_id)\n",
            ");\n",
            "\n",
            "CREATE TABLE Products (\n",
            "    product_id INT PRIMARY KEY,\n",
            "    name TEXT,\n",
            "    price DECIMAL\n",
            ");\n",
            "\n",
            "CREATE TABLE OrderItems (\n",
            "    order_item_id INT PRIMARY KEY,\n",
            "    order_id INT,\n",
            "    product_id INT,\n",
            "    quantity INT,\n",
            "    FOREIGN KEY (order_id) REFERENCES Orders(order_id),\n",
            "    FOREIGN KEY (product_id) REFERENCES Products(product_id)\n",
            ");\n",
            "\n",
            "\n",
            "    ### Samples\n",
            "\n",
            "    Question1: List all customer names.\n",
            "    ```sql\n",
            "    SELECT name FROM Customers;\n",
            "\n",
            "    Question2: Show names of all products that were ordered more than once\n",
            "    ```sql\n",
            "    SELECT p.name\n",
            "    FROM Products p\n",
            "    JOIN OrderItems oi ON p.product_id = oi.product_id\n",
            "    GROUP BY p.name\n",
            "    HAVING SUM(oi.quantity) > 1;\n",
            "\n",
            "    Question3:Retrieve the total number of orders per customer\n",
            "    ```sql\n",
            "    SELECT c.name, COUNT(o.order_id) AS order_count\n",
            "    FROM Customers c\n",
            "    JOIN Orders o ON c.customer_id = o.customer_id\n",
            "    GROUP BY c.name;\n",
            "\n",
            "\n",
            "    ### Response\n",
            "    Based on your instructions, here is the SQL query I have generated to answer the question\n",
            "    `Cuáles son los nombres de todos los clientes que hicieron un pedido en enero`:\n",
            "    ```sql3\n",
            "    \n"
          ]
        }
      ],
      "source": [
        "sp_nl2sql3 = sp_nl2sql3b.format(question=\"Cuáles son los nombres de todos los clientes que hicieron un pedido en enero\")\n",
        "print (sp_nl2sql3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "rBGokR4RFfrK"
      },
      "outputs": [],
      "source": [
        "input_sentences = tokenizer(sp_nl2sql3, return_tensors=\"pt\").to('cuda')\n",
        "response = get_outputs(foundation_model, input_sentences, max_new_tokens=400)\n",
        "SQL = tokenizer.batch_decode(response, skip_special_tokens=True)\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "OEoQgcoUHXXJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6c7e3fa-e42a-41d2-ba13-957a13350ca4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT c.name, COUNT(o.order_id) AS order_count\n",
            "    FROM Customers c\n",
            "    JOIN Orders o ON c.customer_id = o.customer_id\n",
            "    WHERE o.order_date BETWEEN '2020-01-01' AND '2020-01-31'\n",
            "    GROUP BY c.name\n",
            "    HAVING COUNT(o.order_id) > 0;\n"
          ]
        }
      ],
      "source": [
        "print(SQL[0].split(\"```sql3\")[-1].split(\"```\")[0].split(\";\")[0].strip() + \";\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHZn6nGCH2RS"
      },
      "source": [
        "The generated SQL command is the same regardless of where we have placed the examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrHGZjraCYSR"
      },
      "source": [
        "#Conclusions.\n",
        "\n",
        "Let's see the three SQL's together.\n",
        "\n",
        "* SELECT employees.name, MAX(salary.salary) AS max_salary FROM employees JOIN salary ON employees.ID_Usr = salary.ID_Usr GROUP BY employees.name ORDER BY max_salary DESC NULLS LAST LIMIT 1;\n",
        "\n",
        "* SELECT e.name\n",
        "    FROM employees e\n",
        "    JOIN salary s ON e.ID_Usr = s.ID_usr\n",
        "    WHERE s.salary = (SELECT MAX(salary) FROM salary);\n",
        "\n",
        "* SELECT e.name\n",
        "    FROM employees e\n",
        "    JOIN salary s ON e.ID_Usr = s.ID_usr\n",
        "    WHERE s.salary = (SELECT MAX(salary) FROM salary);\n",
        "\n",
        "* Spanish Question: SELECT e.name\n",
        "     FROM employees e\n",
        "     JOIN salary s ON e.ID_Usr = s.ID_Usr\n",
        "     WHERE s.salary = (SELECT MAX(salary) FROM salary)\n",
        "     GROUP BY e.name\n",
        "     ORDER BY COUNT(studies.ID_study) DESC\n",
        "     LIMIT 1;\n",
        "\n",
        "\n",
        "**The model has demonstrated that it is highly efficient in crafting SQL.** Additionally, it pays a lot of attention, perhaps too much, to the examples we provide. Clearly, these examples should be crafted by one of the best SQL programmers we have access to, though their use may not be essential.\n",
        "\n",
        "On the other hand, although the model is clearly very proficient in SQL generation, during the creation of the notebook, I have encountered several issues because the commands need to be extremely clear. It doesn't handle typos well (which should not exist).\n",
        "\n",
        "It appears to have some issues when it receives commands in Spanish. I assume this problem would be present in any language other than English. Therefore, since it's a tool that could be used by non-technical personnel, this should be considered in environments where English is not the primary language."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P45ukTZyHdFE"
      },
      "source": [
        "# Exercise\n",
        " - Complete the prompts similar to what we did in class.\n",
        "     - Try at least 3 versions\n",
        "     - Be creative\n",
        " - Write a one page report summarizing your findings.\n",
        "     - Were there variations that didn't work well? i.e., where GPT either hallucinated or wrong\n",
        " - What did you learn?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Version 1"
      ],
      "metadata": {
        "id": "GHggD5ozA2vv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "T7t6MCIiwhsL"
      },
      "outputs": [],
      "source": [
        "sp_nl2sql_v1 = \"\"\"\n",
        "    ### Instructions:\n",
        "Your task is convert a question into a SQL query, given a SQL database schema.\n",
        "Adhere to these rules:\n",
        "- **Deliberately go through the question and database schema word by word** to appropriately answer the question\n",
        "\n",
        "    ### Input\n",
        "    Generate a SQL query that answers the question below.\n",
        "    This query will run on a database whose schema is represented in this string:\n",
        "\n",
        "CREATE TABLE Customers (\n",
        "    customer_id INT PRIMARY KEY,\n",
        "    name TEXT,\n",
        "    email TEXT\n",
        ");\n",
        "CREATE TABLE Orders (\n",
        "    order_id INT PRIMARY KEY,\n",
        "    customer_id INT,\n",
        "    order_date DATE,\n",
        "    total_amount DECIMAL,\n",
        "    FOREIGN KEY (customer_id) REFERENCES Customers(customer_id)\n",
        ");\n",
        "\n",
        "  ### Response\n",
        "    Based on your instructions, here is the SQL query I have generated to answer the question\n",
        "    `{question}`:\n",
        "    ```sql3\n",
        "    \"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sp_nl2sql_v1_ = sp_nl2sql_v1.format(question=\"What are the names of customers who have placed more than 3 orders and spent over 500 in total\")\n",
        "print (sp_nl2sql_v1_)"
      ],
      "metadata": {
        "id": "vnHI0SF9FeLQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a100bbfe-6ed9-4ea1-875d-14bfce171f80"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    ### Instructions:\n",
            "Your task is convert a question into a SQL query, given a SQL database schema.\n",
            "Adhere to these rules:\n",
            "- **Deliberately go through the question and database schema word by word** to appropriately answer the question\n",
            "\n",
            "    ### Input\n",
            "    Generate a SQL query that answers the question below.\n",
            "    This query will run on a database whose schema is represented in this string:\n",
            "\n",
            "CREATE TABLE Customers (\n",
            "    customer_id INT PRIMARY KEY,\n",
            "    name TEXT,\n",
            "    email TEXT\n",
            ");\n",
            "CREATE TABLE Orders (\n",
            "    order_id INT PRIMARY KEY,\n",
            "    customer_id INT,\n",
            "    order_date DATE,\n",
            "    total_amount DECIMAL,\n",
            "    FOREIGN KEY (customer_id) REFERENCES Customers(customer_id)\n",
            ");\n",
            "\n",
            "  ### Response\n",
            "    Based on your instructions, here is the SQL query I have generated to answer the question\n",
            "    `What are the names of customers who have placed more than 3 orders and spent over 500 in total`:\n",
            "    ```sql3\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sentences = tokenizer(sp_nl2sql_v1_, return_tensors=\"pt\").to('cuda')\n",
        "response = get_outputs(foundation_model, input_sentences, max_new_tokens=400)\n",
        "SQL = tokenizer.batch_decode(response, skip_special_tokens=True)\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "iN_2U4AyX5ov"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(SQL[0].split(\"```sql3\")[-1].split(\"```\")[0].split(\";\")[0].strip() + \";\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nz6mxuflX5h1",
        "outputId": "f0aa6c6f-3b54-4370-f99d-0507f709bb07"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT c.name, COUNT(o.order_id) AS order_count, SUM(o.total_amount) AS total_spent FROM Customers c JOIN Orders o ON c.customer_id = o.customer_id GROUP BY c.name HAVING COUNT(o.order_id) > 3 AND SUM(o.total_amount) > 500;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Version 2"
      ],
      "metadata": {
        "id": "6oYuInteA7HZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sp_nl2sql_v2 = \"\"\"\n",
        "### Instructions:\n",
        "Your task is convert a question into a SQL query, given a SQL database schema.\n",
        "Adhere to these rules:\n",
        "- **Deliberately go through the question and database schema word by word** to appropriately answer the question\n",
        "\n",
        "    ### Input\n",
        "    Generate a SQL query that answers the question below.\n",
        "    This query will run on a database whose schema is represented in this string:\n",
        "\n",
        "CREATE TABLE Customers (\n",
        "    customer_id INT PRIMARY KEY,\n",
        "    name TEXT,\n",
        "    email TEXT\n",
        ");\n",
        "CREATE TABLE Orders (\n",
        "    order_id INT PRIMARY KEY,\n",
        "    customer_id INT,\n",
        "    order_date DATE,\n",
        "    total_amount DECIMAL,\n",
        "    FOREIGN KEY (customer_id) REFERENCES Customers(customer_id)\n",
        ");\n",
        "\n",
        "    ### Response\n",
        "\n",
        "    Question1: List all customer names.\n",
        "    ```sql\n",
        "    SELECT name FROM Customers;\n",
        "\n",
        "    Question2:Retrieve the total number of orders per customer\n",
        "    ```sql\n",
        "    SELECT c.name, COUNT(o.order_id) AS order_count\n",
        "    FROM Customers c\n",
        "    JOIN Orders o ON c.customer_id = o.customer_id\n",
        "    GROUP BY c.name;\n",
        "\n",
        "\n",
        "\n",
        "    Based on your instructions, here is the SQL query I have generated to answer the question\n",
        "    `{question}`:\n",
        "    ```sql3\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "cvNmUIayA8Vm"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sp_nl2sql_v2_ = sp_nl2sql_v2.format(question=\"What are the names of customers who have placed more than 3 orders and spent over 500 in total\")\n",
        "print (sp_nl2sql_v2_)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "2Wl2HQVnFNcX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a65b2367-6542-46e9-f740-536be4810082"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### Instructions:\n",
            "Your task is convert a question into a SQL query, given a SQL database schema.\n",
            "Adhere to these rules:\n",
            "- **Deliberately go through the question and database schema word by word** to appropriately answer the question\n",
            "\n",
            "    ### Input\n",
            "    Generate a SQL query that answers the question below.\n",
            "    This query will run on a database whose schema is represented in this string:\n",
            "\n",
            "CREATE TABLE Customers (\n",
            "    customer_id INT PRIMARY KEY,\n",
            "    name TEXT,\n",
            "    email TEXT\n",
            ");\n",
            "CREATE TABLE Orders (\n",
            "    order_id INT PRIMARY KEY,\n",
            "    customer_id INT,\n",
            "    order_date DATE,\n",
            "    total_amount DECIMAL,\n",
            "    FOREIGN KEY (customer_id) REFERENCES Customers(customer_id)\n",
            ");\n",
            "\n",
            "    ### Response\n",
            "\n",
            "    Question1: List all customer names.\n",
            "    ```sql\n",
            "    SELECT name FROM Customers;\n",
            "\n",
            "    Question2:Retrieve the total number of orders per customer\n",
            "    ```sql\n",
            "    SELECT c.name, COUNT(o.order_id) AS order_count\n",
            "    FROM Customers c\n",
            "    JOIN Orders o ON c.customer_id = o.customer_id\n",
            "    GROUP BY c.name;\n",
            "\n",
            "\n",
            "\n",
            "    Based on your instructions, here is the SQL query I have generated to answer the question\n",
            "    `What are the names of customers who have placed more than 3 orders and spent over 500 in total`:\n",
            "    ```sql3\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sentences = tokenizer(sp_nl2sql_v2_, return_tensors=\"pt\").to('cuda')\n",
        "response = get_outputs(foundation_model, input_sentences, max_new_tokens=400)\n",
        "SQL = tokenizer.batch_decode(response, skip_special_tokens=True)\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "jMN2OHeHWwbp"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(SQL[0].split(\"```sql3\")[-1].split(\"```\")[0].split(\";\")[0].strip() + \";\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaotTRjjWwR3",
        "outputId": "9a504697-584a-42a8-fd0d-a2925aeb1694"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT c.name, COUNT(o.order_id) AS order_count, SUM(o.total_amount) AS total_spent\n",
            "     FROM Customers c\n",
            "     JOIN Orders o ON c.customer_id = o.customer_id\n",
            "     GROUP BY c.name\n",
            "     HAVING COUNT(o.order_id) > 3 AND SUM(o.total_amount) > 500;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Version 3"
      ],
      "metadata": {
        "id": "rb-Q5MDlA8oE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sp_nl2sql_v3 = \"\"\"\n",
        "   ### Instructions:\n",
        "Your task is convert a question into a SQL query, given a SQL database schema.\n",
        "Adhere to these rules:\n",
        "- **Deliberately go through the question and database schema word by word** to appropriately answer the question\n",
        "\n",
        "    ### Input\n",
        "    Generate a SQL query that answers the question below.\n",
        "    This query will run on a database whose schema is represented in this string:\n",
        "\n",
        "CREATE TABLE Customers (\n",
        "    customer_id INT PRIMARY KEY,\n",
        "    name TEXT,\n",
        "    email TEXT\n",
        ");\n",
        "CREATE TABLE Orders (\n",
        "    order_id INT PRIMARY KEY,\n",
        "    customer_id INT,\n",
        "    order_date DATE,\n",
        "    total_amount DECIMAL,\n",
        "    FOREIGN KEY (customer_id) REFERENCES Customers(customer_id)\n",
        ");\n",
        "\n",
        "     ### Response\n",
        "\n",
        "    Question1: List all customer names.\n",
        "    ```sql\n",
        "    SELECT name FROM Customers;\n",
        "\n",
        "    Question2:Retrieve the total number of orders per customer\n",
        "    ```sql\n",
        "    SELECT c.name, COUNT(o.order_id) AS order_count\n",
        "    FROM Customers c\n",
        "    JOIN Orders o ON c.customer_id = o.customer_id\n",
        "    GROUP BY c.name;\n",
        "\n",
        "    Question 3: Find customers who have spent more than 500 in total in the year 2023.\n",
        "    ```sql\n",
        "    SELECT Customers.name\n",
        "    FROM Customers\n",
        "    JOIN Orders ON Customers.customer_id = Orders.customer_id\n",
        "    WHERE Orders.order_date BETWEEN '2023-01-01' AND '2023-12-31'\n",
        "    GROUP BY Customers.name\n",
        "    HAVING SUM(Orders.total_amount) > 500;\n",
        "\n",
        "\n",
        "\n",
        "    Based on your instructions, here is the SQL query I have generated to answer the question\n",
        "    `{question}`:\n",
        "    ```sql3\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "XFYZAzQjA9SI"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sp_nl2sql_v3_ = sp_nl2sql_v3.format(question=\"What are the names of customers who have placed more than 3 orders and spent over 500 in total\")\n",
        "print (sp_nl2sql_v2_)"
      ],
      "metadata": {
        "id": "cyTIEoBAOu08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15b97262-df11-43f3-d3ce-7d22326ade4e"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### Instructions:\n",
            "Your task is convert a question into a SQL query, given a SQL database schema.\n",
            "Adhere to these rules:\n",
            "- **Deliberately go through the question and database schema word by word** to appropriately answer the question\n",
            "\n",
            "    ### Input\n",
            "    Generate a SQL query that answers the question below.\n",
            "    This query will run on a database whose schema is represented in this string:\n",
            "\n",
            "CREATE TABLE Customers (\n",
            "    customer_id INT PRIMARY KEY,\n",
            "    name TEXT,\n",
            "    email TEXT\n",
            ");\n",
            "CREATE TABLE Orders (\n",
            "    order_id INT PRIMARY KEY,\n",
            "    customer_id INT,\n",
            "    order_date DATE,\n",
            "    total_amount DECIMAL,\n",
            "    FOREIGN KEY (customer_id) REFERENCES Customers(customer_id)\n",
            ");\n",
            "\n",
            "    ### Response\n",
            "\n",
            "    Question1: List all customer names.\n",
            "    ```sql\n",
            "    SELECT name FROM Customers;\n",
            "\n",
            "    Question2:Retrieve the total number of orders per customer\n",
            "    ```sql\n",
            "    SELECT c.name, COUNT(o.order_id) AS order_count\n",
            "    FROM Customers c\n",
            "    JOIN Orders o ON c.customer_id = o.customer_id\n",
            "    GROUP BY c.name;\n",
            "\n",
            "\n",
            "\n",
            "    Based on your instructions, here is the SQL query I have generated to answer the question\n",
            "    `What are the names of customers who have placed more than 3 orders and spent over 500 in total`:\n",
            "    ```sql3\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sentences = tokenizer(sp_nl2sql_v3_, return_tensors=\"pt\").to('cuda')\n",
        "response = get_outputs(foundation_model, input_sentences, max_new_tokens=400)\n",
        "SQL = tokenizer.batch_decode(response, skip_special_tokens=True)\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "iIyw6hKCXlaG"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(SQL[0].split(\"```sql3\")[-1].split(\"```\")[0].split(\";\")[0].strip() + \";\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93Ctbmo-Xo-q",
        "outputId": "cf5967ac-c2ca-43da-be92-c7042fe5c417"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT Customers.name\n",
            "    FROM Customers\n",
            "    JOINOrders ON Customers.customer_id =Orders.customer_id\n",
            "    WHEREOrders.order_date BETWEEN '2023-01-01' AND '2023-12-31'\n",
            "    GROUP BY Customers.name\n",
            "    HAVING COUNT(Orders.order_id) > 3 AND SUM(Orders.total_amount) > 500;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SQL Prompt Engineering Evaluation Report\n",
        "\n",
        "## Task Description\n",
        "The goal was to evaluate the performance of three prompt variations designed to convert a natural language question into a valid SQL query.  \n",
        "The question used in all prompts was:\n",
        "\n",
        "> **\"What are the names of customers who have placed more than 3 orders and spent over 500 in total?\"**\n",
        "\n",
        "The database schema included:\n",
        "- `Customers(customer_id, name, email)`\n",
        "- `Orders(order_id, customer_id, order_date, total_amount)`\n",
        "\n",
        "---\n",
        "\n",
        "## Prompt Versions\n",
        "\n",
        "###**Version 1**\n",
        "\n",
        "Correct and concise\n",
        "\n",
        "Matches the intent of the question accurately.\n",
        "\n",
        "No hallucinations or irrelevant conditions.\n",
        "\n",
        "### **Version 2**\n",
        "\n",
        "Also correct\n",
        "\n",
        "Nearly identical to Version 1.\n",
        "\n",
        "### **Version 3**\n",
        "\n",
        "Issues found:\n",
        "\n",
        "Formatting errors: no spaces between SQL keywords (e.g., JOINOrders, WHEREOrders)\n",
        "\n",
        "Added a filter for 2023 not mentioned in the question → hallucination\n",
        "\n",
        "Resulting query does not match the question's intent"
      ],
      "metadata": {
        "id": "ewC87P2o_tTu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w08b9_YDaGSK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7cfbbcb63b8a47ff90cb3d69d09c9171": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_32a88bfad79348d5b4af4aebf05ea870",
              "IPY_MODEL_9891886f7e34422dad03b38dba8a942b",
              "IPY_MODEL_07e11b7506764d89a0d51a36d7d04baf"
            ],
            "layout": "IPY_MODEL_45f367376a96490a9203a4a664f715b7"
          }
        },
        "32a88bfad79348d5b4af4aebf05ea870": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8942b4deb354824993d92a2cb78dae6",
            "placeholder": "​",
            "style": "IPY_MODEL_f24918c49953451386f682499bf1b0c5",
            "value": "Fetching 2 files: 100%"
          }
        },
        "9891886f7e34422dad03b38dba8a942b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6f9f6548ecb4195ae76b4eff9d3c1e4",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_01b9d2d4354242df9ed6f112c5171d29",
            "value": 2
          }
        },
        "07e11b7506764d89a0d51a36d7d04baf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bffd7a3c78b341b9b510453d56321c91",
            "placeholder": "​",
            "style": "IPY_MODEL_816bc43de88245f98747cf6281a6a10c",
            "value": " 2/2 [00:14&lt;00:00, 14.11s/it]"
          }
        },
        "45f367376a96490a9203a4a664f715b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8942b4deb354824993d92a2cb78dae6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f24918c49953451386f682499bf1b0c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6f9f6548ecb4195ae76b4eff9d3c1e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01b9d2d4354242df9ed6f112c5171d29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bffd7a3c78b341b9b510453d56321c91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "816bc43de88245f98747cf6281a6a10c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f0890da1d9d49a7a6eeabe5ddf6db21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_05652939a26f48bdbed892a75a1582c5",
              "IPY_MODEL_d73d76d7a13f40f6bd705a3590d0f283",
              "IPY_MODEL_70d51cd1a265482da0d0b555c0dafd86"
            ],
            "layout": "IPY_MODEL_fef14a182cf54e1a8bfe5668d66c40fa"
          }
        },
        "05652939a26f48bdbed892a75a1582c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b93cfb0c5674adf82d20f35bd1802d9",
            "placeholder": "​",
            "style": "IPY_MODEL_066a7547905f41f0b3bc7593ccd91ddb",
            "value": "pytorch_model-00001-of-00002.bin: 100%"
          }
        },
        "d73d76d7a13f40f6bd705a3590d0f283": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb095a039b394ebeba30847d4fb37f7b",
            "max": 9943030860,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7034033f53fe4d43a6d6a9272cbd7cd5",
            "value": 9943030860
          }
        },
        "70d51cd1a265482da0d0b555c0dafd86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23ae95fe17334ee1b46b7bf5b6b976c1",
            "placeholder": "​",
            "style": "IPY_MODEL_9151606613b3484f80e3f7676cfd9e2d",
            "value": " 9.94G/9.94G [00:13&lt;00:00, 22.3MB/s]"
          }
        },
        "fef14a182cf54e1a8bfe5668d66c40fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b93cfb0c5674adf82d20f35bd1802d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "066a7547905f41f0b3bc7593ccd91ddb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb095a039b394ebeba30847d4fb37f7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7034033f53fe4d43a6d6a9272cbd7cd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "23ae95fe17334ee1b46b7bf5b6b976c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9151606613b3484f80e3f7676cfd9e2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f2db411b29d430ebc2a0b875e210b23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_799495d8f0a4481eaab853024567efe2",
              "IPY_MODEL_3f06208ca5954d1aa06cd468bbd8a7df",
              "IPY_MODEL_c9dc148940344bcba07953a215006209"
            ],
            "layout": "IPY_MODEL_83cdfaff81d1467fb0dad8147ac87ca2"
          }
        },
        "799495d8f0a4481eaab853024567efe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05dda387758149c8bad4fd8b342b2667",
            "placeholder": "​",
            "style": "IPY_MODEL_0a6ee0ea38124042801d4a3f4de9340d",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "3f06208ca5954d1aa06cd468bbd8a7df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37a5cd5b2e074e9782046ed02ff12c51",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a5eed6c8cf824618b5087ee281002bba",
            "value": 2
          }
        },
        "c9dc148940344bcba07953a215006209": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1ec93f16a5c49e9b31c11850f1d182e",
            "placeholder": "​",
            "style": "IPY_MODEL_14047118b8944f22bef12b626b666a7e",
            "value": " 2/2 [00:17&lt;00:00,  8.15s/it]"
          }
        },
        "83cdfaff81d1467fb0dad8147ac87ca2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05dda387758149c8bad4fd8b342b2667": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a6ee0ea38124042801d4a3f4de9340d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37a5cd5b2e074e9782046ed02ff12c51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5eed6c8cf824618b5087ee281002bba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1ec93f16a5c49e9b31c11850f1d182e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14047118b8944f22bef12b626b666a7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e84cd88ced7b4bcd9619657ac0cb822f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca69fbe6da6d4faea97c525c667a7269",
              "IPY_MODEL_ad44f8a751f94777bf1dba4878623408",
              "IPY_MODEL_722b8a0d17f74a058bf6e718c4d6d1b5"
            ],
            "layout": "IPY_MODEL_10675ff63f1740a0af7e477f879dee41"
          }
        },
        "ca69fbe6da6d4faea97c525c667a7269": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfe1d3c8573742d3b7b74d8bed17fe74",
            "placeholder": "​",
            "style": "IPY_MODEL_ba036d7588dc457e8c5f87a433f6f65b",
            "value": "generation_config.json: 100%"
          }
        },
        "ad44f8a751f94777bf1dba4878623408": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d24e8c001ed4000bcbfd1d72f4a4a17",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ceeca5f73354449f8a61eb96a4d6c695",
            "value": 116
          }
        },
        "722b8a0d17f74a058bf6e718c4d6d1b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52cd63335c27421aa7a808e935779c0f",
            "placeholder": "​",
            "style": "IPY_MODEL_d23dc2035fdb430ca93b39acff435691",
            "value": " 116/116 [00:00&lt;00:00, 15.3kB/s]"
          }
        },
        "10675ff63f1740a0af7e477f879dee41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfe1d3c8573742d3b7b74d8bed17fe74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba036d7588dc457e8c5f87a433f6f65b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d24e8c001ed4000bcbfd1d72f4a4a17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ceeca5f73354449f8a61eb96a4d6c695": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "52cd63335c27421aa7a808e935779c0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d23dc2035fdb430ca93b39acff435691": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}